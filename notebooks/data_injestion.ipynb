{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402b8319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/happyuser/vscode/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "from doman_dict import full_domain_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497752eb",
   "metadata": {},
   "source": [
    "## loading and prasing resume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resumes.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "parsed_data = {}\n",
    "\n",
    "def extract_resume_category(url: str) -> str:\n",
    "    match = re.search(r\"/resume-database/\\d+-([a-zA-Z0-9-]+)/\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "for key, value in data.items():\n",
    "    role = extract_resume_category(key)  # e.g., \"oracle-resumes\"\n",
    "\n",
    "    # Initialize list if role not in parsed_data\n",
    "    if role not in parsed_data:\n",
    "        parsed_data[role] = []\n",
    "\n",
    "    # Append the current resume to the list\n",
    "    parsed_data[role].append(value)\n",
    "\n",
    "list(parsed_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce0f7a",
   "metadata": {},
   "source": [
    "## below code gives the relavant job role given a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4991851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_match(input_string: str, data_dict: dict):\n",
    "    input_string = input_string.lower()\n",
    "    best_score = 0\n",
    "    best_key = None\n",
    "    best_value = None\n",
    "\n",
    "    for key, values in data_dict.items():\n",
    "        if not isinstance(values, list):\n",
    "            values = [values]\n",
    "        \n",
    "        # Compare input_string against all values in the list using char-level similarity\n",
    "        match, score, _ = process.extractOne(input_string, values, scorer=fuzz.ratio)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_key = key\n",
    "            best_value = match\n",
    "\n",
    "    return best_key, best_value, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c906b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enterprise-apps', 'oracle-developer')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_key, best_value, _ = lexical_match(\"ORACLE DeveLoper\", full_domain_mapping)\n",
    "best_key, best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44bfb2f",
   "metadata": {},
   "source": [
    "## data engineering new resume data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26a87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_resume.json\", \"r\") as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc98228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in json_data.items():\n",
    "    role = extract_resume_category(key)  # e.g., \"oracle-resumes\"\n",
    "\n",
    "    # Initialize list if role not in parsed_data\n",
    "    if role not in parsed_data:\n",
    "        parsed_data[role] = []\n",
    "\n",
    "    parsed_data[role].append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "997555ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data_job1 = parsed_data[\"oracle-resumes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2485010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'OBJECTIVE': ['To work in fast paced dynamic environment to align my professional Oracle PLSQL skills with a progressive company wherein the application of my technical education and work ethics that would provide a significant contribution to the company’s continued success and thereby adding value to the organization.'], 'SUMMARY': ['Having 7 years of experience as Oracle PL/SQL developer and implementation of applications using Oracle Applications. Strong experience in Oracle RDBMS, PLSQL Development, Oracle 9i,10g,11g, SQL, PL/SQL, Developer 2000/Forms and Report 10g/6i, Java, HTML, UNIX and Workflow.', 'Experience in Design, Development, Implementation and support as Oracle Developer in Production, Development and Test Environments using Oracle Tools.', 'Experience in using Oracle tools like SQL * Loader, Toad, SQL Navigator, SQL Developer and Data Loader.', 'Developed SQL Loader control programs, interfaces and PL/SQL validation scripts to transfer flat file data into oracle database and Oracle Applications base tables.', 'Experienced in RDBMS design, data modeling, data normalization and SQL tuning using Indexes.', 'Good conceptual knowledge in Data warehouse and STAR Schema.', 'Good knowledge in Creating and Maintaining Database objects like Tables, Indexes, Views, Synonyms, Stored Procedures and Packages.', 'Proficient in writing Stored Procedures, Functions, Packages and Database Triggers using PL/SQL.', 'Experience in Creating and Maintaining Database objects like Tables, Indexes, Views, Synonyms, Stored Procedures and Packages.', 'Experience in Creating Unix Shell script to automate the FTP processes for receiving and sending the files', 'Experience in writing and tuning of complex SQL statements, complex joins and sub - queries.', 'Used SQL Trace, Explain Plan and TK Prof for Better performance.', 'Experience in working with UTL Files and Dynamic SQL.', 'Developed SQL Loader control programs, interfaces and PL/SQL validation scripts to transfer flat file data into oracle database and Oracle Applications base tables.', 'Proficient in Designing and Developing of Forms and Reports using Oracle Forms 10g/9i/6i and Reports 10g/9i/6i.', 'Experience in Design, Development, Implementation and support as Oracle Developer in Production, Development and Test Environments using Oracle Tools like JDeveloper and reporting services using Oracle BI tools.', 'Proficient in designing, modeling, creating and maintaining Oracle database.', 'Excellent logical and analytical skills, interpersonal & communication skills and strong ability to perform as part of a team.'], 'TECHNICAL SKILLS': {'Operating Systems': 'DOS, Windows XP/NT,Vista,7 Sun, AIX, Linux, UNIX', 'Languages': 'SQL, PLSQL, C, C++, COBOL, Java, VB .Net', 'Scripting Languages': 'JavaScript, Perl, HTML and XML', 'GUI’s Technologies': 'Oracle Forms and Reports 10g/9i/6i, Oracle Designer 2000, Crystal Reports 9/10, Discoverer10g, Erwin, ODI, J2EE (Servlets, JSP, JDBC), Oracle APEX', 'Databases': 'Oracle 9i/10g/11g, SQL server 2000, Oracle XML DB, Oracle AIX, Oracle AQ, MS Access', 'SCM Tools': 'Subversion, CVS, ClearQuest, JIRA', 'Utilities': 'SQL* Plus, SQL* Loader, SQL Navigator, Toad, UTL File, ETL tools Informatica Power Center, OEM'}, 'PROFESSIONAL EXPERIENCE': [{'company_name': 'Confidential, Deerfield, IL', 'job_role': 'Oracle PL/SQL Developer', 'Responsibilities:': '', 'Environment:': ['Identified tables, Indexes, Stored Procedures, triggers, Constraints and Data types of the existing SQL Server database.', 'Came up with the low level detailed design to re-create the objects to Oracle database.', 'Implemented and fine tuned the detailed design to fit into the migration process.', 'Created and managed primary data base objects such as Tables, Views, Indexes, Sequences, and Synonyms according to corresponding Data types', 'Developed PL/SQL code to implement business rules through cursors, ref cursors, procedures, functions, and packages', 'Migrated data from flat files to Oracle database using SQL*Loader', 'Developed control files for SQL * Loader and PL/SQL scripts for Data Extraction/Transformation/Loading and Mapping, loading data into interface tables from different Legacy systems and validating the data.', 'Efficiently developed Conceptual, Logical Data models and transformed them to Physical Data model and Creating Schemas using ERWIN.', 'Created PL/SQL stored procedures for database and application validations', 'Modified and developed database triggers, cursors, procedures, functions and packages to meet business requirements', 'Involved in performance tuning of SQL queries to decrease the execution time', 'Created test cases PL/SQL procedures for migrated SQL and PL/SQL procedures', 'Used cursor variables to pass query result sets between PL/SQL programs and client application', 'Migrated the reports according to the requirement using Oracle Reports 10g', 'Responsible for writing the technical documents and maintaining the documentation']}, {'company_name': 'Responsibilities:', 'job_role': 'Environment:Oracle 10g, SQL and PL/SQL, SQL * Loader, TOAD, SQL * Plus, Reports 10g, Erwin, ERD', 'Confidential, Pittsburgh, PA': '', 'PL/SQL Developer': ['Involved in analysis, design, coding, and implementation', 'As a part of Data Mining team provided the data from the database to the Testing teams', 'Written the SQL Queries to Data Retrieval Tool', 'Upon the Requirement updated and modified the queries in the query tool', 'Need to develop the reports everyday from the database to check the accounts migration', 'Extensively used inbuilt Oracle PL/SQL packages like UTL FILE, DBMS PIPE, DBMS SQL, DBMS STATS in application development', 'Developed PL/SQL packages, procedures, functions, materialized views, SQL Scripts and triggers to populate the historic data in the tables applying business logic', 'Extensively involved in writing SQL sub-queries with join conditions and PL/SQL scripts', 'Involved in performance tuning of SQL queries and Created indexes on tables and optimizing Stored procedure queries', 'Developed triggers for automatic updating of the tables and views', 'Created group, tabular, and form reports', 'Used UNIX scripting to automate the process by using CRONTAB.']}, {'company_name': 'Responsibilities:', 'job_role': 'Environment:Oracle 10g, SQL*PLUS, TOAD, SQL*LOADER, Forms 10g, Reports 10g, PL/SQL', 'Confidential, New York': '', 'PL/SQL Developer': ['Actively participated in gathering Business Requirements and System Specification from system users.', 'Based on partially filled reports which comes from CRM department Retrieved the customer data from database', 'Referencing the CUSIP id retrieved the customer policy id, premium amount, policy start date, end date, policy interest rate', 'Written the pl/sql procedures to retrieve the customer information by giving policy id, cusip id as parameters', 'According to given reports, changed the insurance policy by calculating the interest.', 'Updated the policy interest rates by calculating the insurance rate then calculated the interest for next month', 'Developed and updated the reports on different type of bonds like municipal bond, public financial bonds and insurance bonds', 'Customized the reports with the new interest rates as per the business needs', 'Developed and enhanced existing PL/SQL code extensively to suit changing needs', 'Developed new reports using XML publisher in PDF format', 'Used UTL FILE package in PL/SQL to read and write data in text files', 'Wrote scripts to create tables, functions, procedures, ref cursors, triggers and packages', 'Wrote shell scripts for automating the process of data loading and daily process', \"Worked with DBA's to help them in data loading process, batch jobs and various administration tasks\"]}, {'company_name': 'Responsibilities:', 'job_role': 'Environment:Oracle 10g, SQL, PL/SQL, TOAD, SQL*Loader, Reports 10g, XML publisher, SQL * Plus, Unix, Java', 'Confidential, Philadelphia, Pennsylvania': '', 'PL/SQL Developer': ['Gathered and analyzed requirement from business users', 'Created database objects like Tables, Synonyms, Sequences and Views', 'Edited procedures and functions for improved business requirements', 'Wrote complex PL/SQL packages for Customer Interface and Payment Interface and for Oracle Applications', 'Used Materialized Views, Hints, SQL Trace/TkProf, Indexes for query tuning and optimizations', 'Collaborated with data Warehouse Architect in writing SQL scripts, Shell Programs, Data Flows and more', 'Supported development, test and production database', 'Used SQL Developer and TOAD to develop code.', 'Worked with Oracle Forms 10g and Reports 10g.', 'Created Test cases, Technical Design Document, and Install Plans and worked with Release Engineering teams']}, {'company_name': 'Responsibilities:', 'job_role': 'Environment:Oracle 10g, PL/SQL, SQL, ERWIN, Forms 10g, Oracle report 10g, Shell Scripts'}]}, {'SUMMARY': ['IT professional with 9+ years of diverse experience in IT, including business analysis, applications management, strong software development skills and a solid technical aptitude for troubleshooting and problem solving.', 'Excel in identifying system needs, implementing multi - faceted application solutions, and working with a variety of operational systems, software, development languages and tools.'], 'TECHNICAL SKILLS': {'Operating Systems': 'Linux, Unix, IBM AIX 5.3 and Windows 95/98/2000/NT/XP', 'Languages': 'Oracle PL/SQL, UNIX Shell Scripting, Pro C, 4GL', 'Databases': 'Oracle8i, 9i, 10g & 11g, Informix', 'Tools': 'SQL*Plus, SQL* Loader, SQL Developer V 1.5.0.54.40 , CTRL M', 'Supporting Software': 'Borland StarTeam, Putty, Smartbear Code Collaborator V7, Exceed', 'Middleware/Distributed': 'Web services', 'Others': 'HTTP/HTTPS, FTP'}, 'PROFESSIONAL EXPERIENCE': [{'company_name': 'Confidential, San Antonio, TX', 'job_role': 'PLSQL Lead Developer', 'Responsibilities:': '', 'Environment:': ['Writing pl/sql procedure/packages/functions to resolve the daily task related issue to make them atomized.', 'Created scripts to load the data into database tables from flat files using SQL* Loader.', 'Created stored procedures with cursors to generate the reports.', 'Created various complex queries with joins, sub-queries, and nested queries in SQL queries.', 'Involved in loading files to tables using NZLOAD and extensively used NZSQL', 'Involved in production support by efficiently debugging the production issues.', 'Created indexes, constraints, triggers, synonyms in different schema.', 'Worked on Oracle Data dictionaries views to get information related to object', 'Worked on Bulk Collection and Pl/sql table for getting optimal performance.', 'Wrote Shell Scripts to do manipulation on vendor input files and loaded into database table', 'Generating various reports on requirements using PL/SQL, ProC and SQL * plus SPOOL command.', 'Involved in job scheduling using CTRL M.', 'Peer Review of code before turning over to production.', 'Preparation of Unit Test plan.', 'Perform System Testing, Release Testing and deploy the code.', 'Coordinating with onsite, attending regular hand-off and transition meetings for new projects.', 'Providing Knowledge transition on delivered effort to Production Support team.']}, {'company_name': 'Confidential, San Antonio, TX', 'job_role': 'Oracle PL /SQL Developer', 'Responsibilities:': '', 'Environment:': ['To find out bugs in the application and rectify them.', 'To prepare document as per the changes in the code.', 'Developing Unix shell script to validate the input feed files received from different vendors.', 'Used various Shell Scripts and Scheduled jobs in CTRL M to run on regular intervals.', 'Involved in SQL Activities.', 'Involved in Unit testing, Debugging and Integration testing of the application.', 'Peer Review of code before turning over to production.', 'Managing Monthly release for all applications development, bug fixes.', 'Involved in client meetings.', 'Worked as independent contributors.']}, {'company_name': 'Confidential, San Antonio, TX', 'job_role': 'Oracle PL/SQL Developer', 'Responsibilities:': '', 'Environment:': ['Worked on project estimates, resourcing, status updates, project plan updates, and team coordination.', 'Preparation of Checklists, identification of Test Cases, preparing Test Plans.', 'Developed Pro C scripts with embedded pl/sql and sql.', 'Wrote Unix shell scripts to invoke the Pro C executables.', 'Scheduled all scripts in CTRL M.', 'Extensive Knowledge and working of Bulk Collect and Bulk Binding for data retrieval.', 'Wrote complex SQL queries, Sub queries, Cursors and Collections for faster data retrieval.', 'Involved in Performance Tuning for the SQL, PL/SQL scripts.', 'Coordination with the Release Management team to ensure the version control of the scripts execution in Production environment.', 'Provided knowledge transfer to other team members about the new technology and allocation of tasks to the team.', 'Involved in writing technical documentation, and writing test plan.', 'Coordinated with development team, project management, QA and provided necessary support.']}, {'company_name': 'Confidential, San Antonio, TX', 'job_role': 'Oracle PL/SQL Developer', 'Responsibilities:': '', 'Confidential, San Antonio, TX': ['Working up with Service requests/change requests.', 'Impact analysis on existing system and provided appropriate solution.', 'Enhancing existing 4gl scripts to implement the business logic.', 'Structural changes to Informix database objects according to business logic.', 'Wrote Unix shell scripts to validate and manipulate the vendor files.', 'Created Unix Shell Scripts for automating the execution process of 4gl reports.', 'Used File Transfer Protocol (FTP) tool to transfer files from one server to other.', 'Worked on CTRL M for Scheduling Batch Jobs.', 'Involved in Unit testing, Integration test and writing the Test plan.', 'Preparing the technical documentation on changes done.', 'Release notes and Rollout and Backout plan.', 'Trained other team members on the functionality and operability of the application.']}, {'company_name': 'Oracle PL/SQL Developer', 'job_role': 'Responsibilities:', 'Environment:': 'Informix, 4GL, Crystal reports, Unix, Linux, IBM Unix servers running AIX 5.3IBM AIX, Borland Starteam, Putty, Smartbear Code Collaborator V7, Exceed'}]}]\n"
     ]
    }
   ],
   "source": [
    "print(parsed_data_job1[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa6a68a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.06902985074627\n"
     ]
    }
   ],
   "source": [
    "count, total = 0, 0\n",
    "for desp in parsed_data_job1:\n",
    "    if \"PROFESSIONAL EXPERIENCE\" in list(desp.keys()):\n",
    "        for exp in desp[\"PROFESSIONAL EXPERIENCE\"]:\n",
    "            total += 1\n",
    "            if \"job_role\" in list(exp.keys()):\n",
    "                if \"Confidential\" in exp[\"job_role\"] or \"Responsibilities\" in exp[\"job_role\"]:\n",
    "                    count += 1\n",
    "\n",
    "print((count/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1090018",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PROFESSIONAL EXPERIENCE'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m job_1 = json_data[\u001b[38;5;28mlist\u001b[39m(json_data.keys())[\u001b[32m0\u001b[39m]]\n\u001b[32m      2\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m \u001b[43mjob_1\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPROFESSIONAL EXPERIENCE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exp[\u001b[33m\"\u001b[39m\u001b[33mjob_role\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mConfidential\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      5\u001b[39m         count += \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'PROFESSIONAL EXPERIENCE'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for exp in job_1[\"PROFESSIONAL EXPERIENCE\"]:\n",
    "    if exp[\"job_role\"] == \"Confidential\":\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecdcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c252b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02870e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2b178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc8fd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7300/124618795.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "/tmp/ipykernel_7300/124618795.py:6: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  vectorstore = Qdrant(\n"
     ]
    },
    {
     "ename": "ResponseHandlingException",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:134\u001b[39m, in \u001b[36mApiClient.send_inner\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mResponseHandlingException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      6\u001b[39m vectorstore = Qdrant(\n\u001b[32m      7\u001b[39m     client=qdrant_client,\n\u001b[32m      8\u001b[39m     collection_name=\u001b[33m\"\u001b[39m\u001b[33mresume_embeddings\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     embeddings=embedding_function\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m texts = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAI Engineer at Databricks\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMachine Learning Intern at Tesla\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mData Scientist at OpenAI\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/qdrant.py:192\u001b[39m, in \u001b[36mQdrant.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, batch_size, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m added_ids = []\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_ids, points \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_rest_batches(\n\u001b[32m    190\u001b[39m     texts, metadatas, ids, batch_size\n\u001b[32m    191\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     added_ids.extend(batch_ids)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m added_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_client.py:1633\u001b[39m, in \u001b[36mQdrantClient.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1626\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1627\u001b[39m         points = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1628\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_models(\n\u001b[32m   1629\u001b[39m                 points, is_query=\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size=\u001b[38;5;28mself\u001b[39m.local_inference_batch_size\n\u001b[32m   1630\u001b[39m             )\n\u001b[32m   1631\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_remote.py:1911\u001b[39m, in \u001b[36mQdrantRemote.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models.Batch):\n\u001b[32m   1909\u001b[39m     points = models.PointsBatch(batch=points, shard_key=shard_key_selector)\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m http_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoints_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mUpsert returned None result\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1918\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api/points_api.py:987\u001b[39m, in \u001b[36mSyncPointsApi.upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert_points\u001b[39m(\n\u001b[32m    978\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    979\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    982\u001b[39m     point_insert_operations: m.PointInsertOperations = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    983\u001b[39m ) -> m.InlineResponse2006:\n\u001b[32m    984\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[33;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_upsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api/points_api.py:512\u001b[39m, in \u001b[36m_PointsApi._build_for_upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m    511\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse2006\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m/points\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:95\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     94\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:112\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, type_: Type[T]) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmiddleware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n\u001b[32m    115\u001b[39m         retry_after_s = response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mRetry-After\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:250\u001b[39m, in \u001b[36mBaseMiddleware.__call__\u001b[39m\u001b[34m(self, request, call_next)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, call_next: Send) -> Response:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vscode/RAG/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:136\u001b[39m, in \u001b[36mApiClient.send_inner\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._client.send(request)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mResponseHandlingException\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = Qdrant(\n",
    "    client=qdrant_client,\n",
    "    collection_name=\"resume_embeddings\",\n",
    "    embeddings=embedding_function\n",
    ")\n",
    "\n",
    "texts = [\n",
    "    \"AI Engineer at Databricks\",\n",
    "    \"Machine Learning Intern at Tesla\",\n",
    "    \"Data Scientist at OpenAI\"\n",
    "]\n",
    "\n",
    "vectorstore.add_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_section(section_name, collection_name):\n",
    "    \"\"\"Ingests a specific section (e.g., summary, skills) into Qdrant\"\"\"\n",
    "    print(f\"\\n🚀 Ingesting {section_name.upper()} into collection: {collection_name}\")\n",
    "\n",
    "    texts, metadatas, ids = [], [], []\n",
    "\n",
    "    for idx, resume in enumerate(tqdm(resumes, desc=f\"Processing {section_name}\")):\n",
    "        # Fix: handle case where each resume is a string\n",
    "        if isinstance(resume, str):\n",
    "            resume = json.loads(resume)\n",
    "\n",
    "        text = resume.get(section_name, \"\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        texts.append(text)\n",
    "        metadatas.append({\n",
    "            \"resume_id\": idx,\n",
    "            \"section\": section_name\n",
    "        })\n",
    "        ids.append(f\"{section_name}_{idx}\")\n",
    "\n",
    "    if len(texts) == 0:\n",
    "        print(f\"⚠️ No data found for section: {section_name}\")\n",
    "        return\n",
    "\n",
    "    # Create collection in Qdrant\n",
    "    Qdrant.from_texts(\n",
    "        texts=texts,\n",
    "        embedding=embedding_model,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids,\n",
    "        url=QDRANT_URL,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"✅ {section_name} section ingested into Qdrant collection '{collection_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e096d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = RecursiveCharacterTextSplitter(chunk_size=512,chunk_overlap=50)\n",
    "chunks = text_split.split_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
