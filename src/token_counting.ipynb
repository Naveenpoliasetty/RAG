{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab7b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import List\n",
    "def extract_jd_keywords(job_description: str, top_k: int = 50) -> List[str]:\n",
    "    \"\"\"Extract keywords from ONE job description\"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform([job_description])\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = tfidf_matrix.toarray().flatten()\n",
    "    \n",
    "    top_indices = scores.argsort()[-top_k:][::-1]\n",
    "    return [feature_names[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ef07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"Job Description:\n",
    "We are seeking an experienced Oracle Sales Cloud Consultant to support implementation, customization, and optimization of Oracle CX Sales applications. The ideal candidate will work closely with business stakeholders to gather requirements, configure the system, and ensure seamless integration with other Oracle and third-party applications.\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "Implement and configure Oracle Sales Cloud modules (Leads, Opportunities, Accounts, Contacts, and Forecasting).\n",
    "Gather business requirements and translate them into functional solutions.\n",
    "Develop custom reports and dashboards using OTBI/BIP.\n",
    "Collaborate with technical teams for integrations and data migration.\n",
    "Provide end-user training, documentation, and post-implementation support.\n",
    "Required Skills:\n",
    "\n",
    "Hands-on experience in Oracle Sales Cloud (B2B/B2C) implementation and support.\n",
    "Strong understanding of sales automation processes and CRM best practices.\n",
    "Knowledge of OIC, Groovy scripting, and REST/SOAP integrations is a plus.\n",
    "Excellent communication and problem-solving skills.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naveenpoliasetty/Downloads/RAG-1/.venv/lib/python3.12/site-packages/spacy/util.py:922: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.7). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oic', 'oracle', 'cx', 'otbi', 'bip', 'b2b', 'b2c', 'crm', 'integrations', 'customization', 'optimization', 'forecasting', 'dashboards', 'documentation', 'sales', 'implementation', 'rest', 'soap', 'an experienced oracle sales cloud consultant', 'oracle cx sales applications', 'business stakeholders', 'seamless integration', 'other oracle and third-party applications', 'oracle sales cloud modules', 'oracle sales cloud', 'sales automation processes', 'crm best practices', 'groovy scripting', 'rest/soap integrations', 'problem-solving skills', 'cloud', 'support', 'stakeholders', 'modules', 'automation', 'scripting', 'otbi/bip', '(b2b/b2c']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from wordfreq import zipf_frequency\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# English + job boilerplate stopwords\n",
    "STOPWORDS = set(nlp.Defaults.stop_words).union({\n",
    "    \"responsibilities\", \"requirements\", \"requirement\", \"qualification\",\n",
    "    \"qualifications\", \"responsible\", \"candidate\", \"role\", \"position\",\n",
    "    \"skills\", \"ability\", \"abilities\", \"experience\", \"team\", \"work\",\n",
    "    \"years\", \"job\", \"environment\", \"department\"\n",
    "})\n",
    "\n",
    "def is_acronym(token):\n",
    "    return bool(re.fullmatch(r\"[A-Z0-9\\-\\.]{2,}\", token))\n",
    "\n",
    "def is_common_word(word):\n",
    "    \"\"\"\n",
    "    Uses word frequency (Zipf score). Higher = more common.\n",
    "    Common English words have Zipf >= 4.0 typically.\n",
    "    Technical terms tend to have low frequency.\n",
    "    \"\"\"\n",
    "    return zipf_frequency(word.lower(), \"en\") >= 4.0\n",
    "\n",
    "def extract_candidates(text):\n",
    "    doc = nlp(text)\n",
    "    candidates = []\n",
    "\n",
    "    # 1️⃣ Single-token candidates (nouns, proper nouns, acronyms)\n",
    "    for token in doc:\n",
    "        if token.pos_ in (\"NOUN\", \"PROPN\"):\n",
    "            w = token.text.strip()\n",
    "            if len(w) > 1 and w.lower() not in STOPWORDS:\n",
    "                candidates.append(w)\n",
    "        # Acronym pattern\n",
    "        if is_acronym(token.text):\n",
    "            candidates.append(token.text)\n",
    "\n",
    "    # 2️⃣ Multi-word noun chunks (e.g., \"cloud infrastructure\")\n",
    "    for chunk in doc.noun_chunks:\n",
    "        phrase = chunk.text.strip()\n",
    "        # Remove chunks that are entirely stopwords\n",
    "        if not all(w.lower() in STOPWORDS for w in phrase.split()):\n",
    "            candidates.append(phrase)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def score_terms(candidates):\n",
    "    # Count frequency in the JD\n",
    "    freq = Counter([c for c in candidates])\n",
    "\n",
    "    scored = {}\n",
    "    for term, count in freq.items():\n",
    "        # Base score = frequency\n",
    "        score = count\n",
    "\n",
    "        # Boost acronyms (high chance of being tech)\n",
    "        if is_acronym(term):\n",
    "            score *= 2.0\n",
    "\n",
    "        # Penalize common everyday English words\n",
    "        if is_common_word(term):\n",
    "            score *= 0.4\n",
    "\n",
    "        # Boost multi-word technical phrases\n",
    "        if \" \" in term:\n",
    "            score *= 1.3\n",
    "\n",
    "        scored[term] = score\n",
    "\n",
    "    return scored\n",
    "\n",
    "\n",
    "def extract_keywords(text, min_score=0.9):\n",
    "    candidates = extract_candidates(text)\n",
    "    scored = score_terms(candidates)\n",
    "\n",
    "    sorted_terms = sorted(scored.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return [term.lower() for term, score in sorted_terms if score >= min_score]\n",
    "\n",
    "\n",
    "keywords = extract_keywords(jd)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7becfcf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51605ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oracle', 'sales', 'implementation', 'cloud', 'support', 'sales cloud', 'oracle sales', 'gather', 'skills', 'configure', 'requirements', 'business', 'implementation support', 'integrations', 'applications', 'ensure', 'excellent communication', 'data migration', 'excellent', 'ensure seamless', 'description', 'end user', 'end', 'experience', 'documentation', 'develop custom', 'develop', 'description seeking', 'documentation post', 'work closely', 'experience oracle', 'groovy scripting', 'integration', 'implementation customization', 'implement configure', 'implement', 'ideal candidate', 'ideal', 'hands experience', 'hands', 'groovy', 'experienced', 'gather requirements', 'gather business', 'functional solutions', 'functional', 'forecasting gather', 'forecasting', 'dashboards using', 'experienced oracle']\n"
     ]
    }
   ],
   "source": [
    "words = extract_jd_keywords(jd)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c9a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     | Config                    | Base path to find the config file: /Users/naveenpoliasetty/Downloads/RAG-1\n",
      "INFO     | Config                    | Loading config file: /Users/naveenpoliasetty/Downloads/RAG-1/src/core/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naveenpoliasetty/Downloads/RAG-1/.venv/lib/python3.12/site-packages/spacy/util.py:922: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.7). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/naveenpoliasetty/Downloads/RAG-1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     | ReliableBatchWorker       | Loading embedding model: intfloat/e5-base-v2\n",
      "INFO     | sentence_transformers.SentenceTransformer | Use pytorch device_name: mps\n",
      "INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: intfloat/e5-base-v2\n",
      "INFO     | ReliableBatchWorker       | Successfully loaded embedding model: intfloat/e5-base-v2\n",
      "INFO     | ReliableBatchWorker       | Model dimension: 768\n",
      "WARNING  | QdrantManager             | Qdrant connection attempt 1/3 failed: [Errno 61] Connection refused\n",
      "WARNING  | QdrantManager             | Qdrant connection attempt 2/3 failed: [Errno 61] Connection refused\n",
      "WARNING  | QdrantManager             | Qdrant connection attempt 3/3 failed: [Errno 61] Connection refused\n"
     ]
    },
    {
     "ename": "QdrantError",
     "evalue": "Failed to connect to Qdrant after 3 attempts: [Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    208\u001b[39m     sock = socket.create_connection(\n\u001b[32m    209\u001b[39m         address,\n\u001b[32m    210\u001b[39m         timeout,\n\u001b[32m    211\u001b[39m         source_address=source_address,\n\u001b[32m    212\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:134\u001b[39m, in \u001b[36mApiClient.send_inner\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mResponseHandlingException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/src/resume_ingestion/vector_store/qdrant_manager.py:116\u001b[39m, in \u001b[36mQdrantManager._initialize_client\u001b[39m\u001b[34m(self, max_retries)\u001b[39m\n\u001b[32m    111\u001b[39m client = QdrantClient(\n\u001b[32m    112\u001b[39m     host=config.qdrant_host,\n\u001b[32m    113\u001b[39m     port=config.qdrant_port,\n\u001b[32m    114\u001b[39m     timeout=timeout\n\u001b[32m    115\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Test connection\u001b[39;00m\n\u001b[32m    117\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mSuccessfully connected to Qdrant\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_client.py:2210\u001b[39m, in \u001b[36mQdrantClient.get_collections\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   2208\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/qdrant_remote.py:2571\u001b[39m, in \u001b[36mQdrantRemote.get_collections\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   2563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m types.CollectionsResponse(\n\u001b[32m   2564\u001b[39m         collections=[\n\u001b[32m   2565\u001b[39m             GrpcToRest.convert_collection_description(description)\n\u001b[32m   2566\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m description \u001b[38;5;129;01min\u001b[39;00m response\n\u001b[32m   2567\u001b[39m         ]\n\u001b[32m   2568\u001b[39m     )\n\u001b[32m   2570\u001b[39m result: Optional[types.CollectionsResponse] = (\n\u001b[32m-> \u001b[39m\u001b[32m2571\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   2572\u001b[39m )\n\u001b[32m   2573\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mGet collections returned None\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api/collections_api.py:330\u001b[39m, in \u001b[36mSyncCollectionsApi.get_collections\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03mGet list name of all existing collections\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_get_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api/collections_api.py:159\u001b[39m, in \u001b[36m_CollectionsApi._build_for_get_collections\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    158\u001b[39m headers = {}\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse2004\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:95\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:112\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, type_: Type[T]) -> T:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmiddleware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_inner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:250\u001b[39m, in \u001b[36mBaseMiddleware.__call__\u001b[39m\u001b[34m(self, request, call_next)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: Request, call_next: Send) -> Response:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/.venv/lib/python3.12/site-packages/qdrant_client/http/api_client.py:136\u001b[39m, in \u001b[36mApiClient.send_inner\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mResponseHandlingException\u001b[39m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mQdrantError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m         result[role] = \u001b[38;5;28mlen\u001b[39m(points) > \u001b[32m0\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m q = \u001b[43mQdrantManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m dr = [\u001b[33m\"\u001b[39m\u001b[33moracle cloud procurement sme\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moracle cloud hcm consultant\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moracle consultant\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(has_job_roles(q, dr))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/src/resume_ingestion/vector_store/qdrant_manager.py:98\u001b[39m, in \u001b[36mQdrantManager.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Default mapping\u001b[39;00m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m.collections_mapping = {\n\u001b[32m     93\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprofessional_summary\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mprofessional_summaries\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     94\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtechnical_skills\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtechnical_skills\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     95\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexperiences\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mexperiences\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mself\u001b[39m._ensure_collections_exist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/RAG-1/src/resume_ingestion/vector_store/qdrant_manager.py:122\u001b[39m, in \u001b[36mQdrantManager._initialize_client\u001b[39m\u001b[34m(self, max_retries)\u001b[39m\n\u001b[32m    120\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQdrant connection attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt == max_retries - \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m QdrantError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to connect to Qdrant after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m attempts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m     time.sleep(\u001b[32m2\u001b[39m ** attempt)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mQdrantError\u001b[39m: Failed to connect to Qdrant after 3 attempts: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.resume_ingestion.vector_store.qdrant_manager import QdrantManager\n",
    "from typing import Dict, List\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "def has_job_roles(qdrant_manager: QdrantManager, job_roles: List[str]) -> Dict[str, bool]:\n",
    "    \"\"\"\n",
    "    Check whether each job role exists anywhere in Qdrant.\n",
    "    Returns dict: role -> True/False\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "\n",
    "    for role in job_roles:\n",
    "        flt = qmodels.Filter(\n",
    "            must=[\n",
    "                qmodels.FieldCondition(\n",
    "                    key=\"job_role\",\n",
    "                    match=qmodels.MatchValue(value=role.strip().lower())\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        points, _ = qdrant_manager.client.scroll(\n",
    "            collection_name=\"experiences\",\n",
    "            with_payload=False,\n",
    "            with_vectors=False,\n",
    "            scroll_filter=flt,\n",
    "            limit=1\n",
    "        )\n",
    "\n",
    "        result[role] = len(points) > 0\n",
    "\n",
    "    return result\n",
    "\n",
    "q = QdrantManager()\n",
    "\n",
    "dr = [\"oracle cloud procurement sme\", \"oracle cloud hcm consultant\", \"oracle consultant\"]\n",
    "print(has_job_roles(q, dr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53625a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path for imports\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5121455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     | src.utils.logger          | Logging configured for pipeline: app\n",
      "INFO     | src.utils.logger          |  Logger module loaded\n",
      "INFO     | Config                    | Base path to find the config file: /Users/naveenpoliasetty/Downloads/RAG-1\n",
      "INFO     | Config                    | Loading config file: /Users/naveenpoliasetty/Downloads/RAG-1/src/core/config.yaml\n",
      "INFO     | ReliableBatchWorker       | Found 3 documents for 3 requested resume IDs in section 'professional_summary'\n",
      "Found 7391 results\n"
     ]
    }
   ],
   "source": [
    "# Since project root is in sys.path (from Cell 6), use 'src.' prefix\n",
    "from src.resume_ingestion.database import MongoDBManager\n",
    "\n",
    "\n",
    "m = MongoDBManager()\n",
    "\n",
    "ids = ['fbc1ff96-8081-430d-a41b-2f34b9a75c12', 'fb7aadc2-1bfe-441f-a49c-39db4a2b0bdc', '5c0d5af1-246f-443b-8667-bb30603db8d9']\n",
    "\n",
    "# Correct method: get_sections_by_resume_ids (not get_resume_by_ids)\n",
    "res = m.get_sections_by_resume_ids(ids, \"professional_summary\")\n",
    "print(f\"Found {len(res)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aec6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    {\\n        \"professional_summary_1\": [\\n            \"7+ years of experience as Oracle PL/SQL Developer with expertise in design, development, testing and deployment of applications built on top of Oracle Database and also involved in support DBA activities.\",\\n            \"Experience in working with Oracle 9i, 10g and 11g database.\",\\n            \"Experience in Database design using Normalization and E/R Diagrams.\",\\n            \"Experience includes extensive coding in PL/SQL, developing Packages, Procedures & Functions including Cursors and Exception handling.\",\\n            \"Experience in writing database triggers & anonymous SQL scripts.\",\\n            \"Expertise in using user defined and system defined Exceptions for Error handling.\",\\n            \"Experience in using Oracle supplied packages such as DBMS FLASHBACK, DBMS SQL, DBMS JOB, UTL FILE for file handling.\",\\n            \"Experience also includes writing sub queries and advanced SQL queries.\",\\n            \"Experience in using Regular expression functions, string handling functions, aggregate functions etc.\",\\n            \"Experience in Performance tuning (both SQL and PL - SQL Tuning) techniques using tools provided by Oracle like EXPLAIN PLAN, SQL*TRACE, TKPROF, AUTOTRACE, ORACLE HINTS etc.\",\\n            \"Used Cost-Based Optimization (CBO).\",\\n            \"Implemented PL/SQL advanced topics like Bulk Collects, Bulk Inserts Ref Cursors, Collections, Dynamic SQL.\",\\n            \"Well versed with Oracle 11g PL/SQL new features.\",\\n            \"Experience in the oracle Flashback techniques for restoring data using timestamp and SCN, flashback version query and transaction query.\",\\n            \"Experience in managing Users, privileges and roles.\",\\n            \"Experience in handling administrative tasks like table space management, User Management and database monitoring tasks.\",\\n            \"Experience in Working with Backups both Logical and physical.\",\\n            \"Experience in Recovering data from user errors using Flashback Technology.\",\\n            \"Experience in Using RMAN for Backup and Recovery.\",\\n            \"Refreshing development/test database from production using Export/Import. This was done so that the latest data is available in the development/test database.\",\\n            \"Supported variety of critical and complex custom applications using Oracle databases and tools in Linux, UNIX and Window environments.\",\\n            \"Involved in project development following SDLC starting from Analysis, Requirements, Design, Coding, Implementation and Support.\",\\n            \"Extensive knowledge of New Business modules and Underwriter Workbench for Variable Universal Life Insurance products. Have a good understanding of Policy Servicing modules.\",\\n            \"24 X 7 Production Database on Call Support.\",\\n            \"Have a good understanding on Service Management modules like Incident, Problem and Change Management.\",\\n            \"Received Global excellence award for outstanding contribution to the production support team for Managed Services to Confidential Insurance, USA.\",\\n            \"Possess a sound understanding of the challenges in Production environment, combined with leadership ability, team player and creative problem solving skills in both strategic and tactical areas.\",\\n            \"Strong interpersonal and problem solving skills.\"\\n        ]\\n    },\\n    {\\n        \"professional_summary_2\": [\\n            \"Overall 11+ years of experience in Information Technology and Manufacturing domain.\",\\n            \"Having 8+ years of extensive experience in IT industry as Oracle applications VCP/SCM/MFG functional consultant and 3 Years of Manufacturing Domain experience.\",\\n            \"Proficient in ASCP, GOP, Rapid Planning, Inventory, Purchasing, Order Management, BOM,WIP and Knowledge in APCC, Inventory Optimization (IO), General Ledger, Advanced Pricing, Costing and i Supplier.\",\\n            \"Effectively involved in Requirement gathering, analyzing business requirements, System Mapping, Conference Room Pilot and Postproduction support.\",\\n            \"4 Full life cycle implementation of Oracle E - Business Suite (MFG & SCM modules) & VCP Modules including design, setup, development, implementation and support of manufacturing systems, with excellent knowledge on VCP/MFG/SCM modules.\",\\n            \"Extensive Experience in Oracle Business flows Procure to Pay (P2P) and Order to Cash (O2C).\",\\n            \"Effectively involved in Oracle EBS R12& VCP Implementation, Enhancement and Production Support Projects.\",\\n            \"Involved in preparation of various Functional Design Documents like MD050 for customizations by using AIM Methodology.\",\\n            \"Experience in the preparation of Functional Design documents for Extensions, Data Conversion/Migrations, Inbound / Outbound interfaces.\",\\n            \"Having very good knowledge in Preparing of different Documents by using Oracle Applications Implementation Methodology (AIM).\",\\n            \"Involved in Unit, Integration (SIT), and User Acceptance Testing (UAT) through the development of test scripts\",\\n            \"Good communication and Inter-Personal Skills and able to work as an active member maintaining good interaction with client and team members.\",\\n            \"Great learning skills to adapt the rapid changing technologies and implementing the same at work.\"\\n        ]\\n    },\\n    {\\n        \"professional_summary_3\": [\\n            \"Overall 11+ years of experience in Information Technology and Manufacturing domain.\",\\n            \"Having 8+ years of extensive experience in IT industry as Oracle applications VCP/SCM/MFG functional consultant and 3 Years of Manufacturing Domain experience.\",\\n            \"Proficient in ASCP, GOP, Rapid Planning, Inventory, Purchasing, Order Management, BOM,WIP and Knowledge in APCC, Inventory Optimization (IO), General Ledger, Advanced Pricing, Costing and i Supplier.\",\\n            \"Effectively involved in Requirement gathering, analyzing business requirements, System Mapping, Conference Room Pilot and Postproduction support.\",\\n            \"4 Full life cycle implementation of Oracle E - Business Suite (MFG & SCM modules) & VCP Modules including design, setup, development, implementation and support of manufacturing systems, with excellent knowledge on VCP/MFG/SCM modules.\",\\n            \"Extensive Experience in Oracle Business flows Procure to Pay (P2P) and Order to Cash (O2C).\",\\n            \"Effectively involved in Oracle EBS R12& VCP Implementation, Enhancement and Production Support Projects.\",\\n            \"Involved in preparation of various Functional Design Documents like MD050 for customizations by using AIM Methodology.\",\\n            \"Experience in the preparation of Functional Design documents for Extensions, Data Conversion/Migrations, Inbound / Outbound interfaces.\",\\n            \"Having very good knowledge in Preparing of different Documents by using Oracle Applications Implementation Methodology (AIM).\",\\n            \"Involved in Unit, Integration (SIT), and User Acceptance Testing (UAT) through the development of test scripts\",\\n            \"Good communication and Inter-Personal Skills and able to work as an active member maintaining good interaction with client and team members.\",\\n            \"Great learning skills to adapt the rapid changing technologies and implementing the same at work.\"\\n        ]\\n    }\\n]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28004e9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50431a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naveenpoliasetty/Downloads/RAG-1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/naveenpoliasetty/Downloads/RAG-1/.venv/lib/python3.12/site-packages/spacy/util.py:922: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.7). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     | src.core.db_manager       | Initializing Qdrant connection...\n",
      "INFO     | ReliableBatchWorker       | Loading embedding model: intfloat/e5-base-v2\n",
      "INFO     | sentence_transformers.SentenceTransformer | Use pytorch device_name: mps\n",
      "INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: intfloat/e5-base-v2\n",
      "INFO     | ReliableBatchWorker       | Successfully loaded embedding model: intfloat/e5-base-v2\n",
      "INFO     | ReliableBatchWorker       | Model dimension: 768\n",
      "INFO     | QdrantManager             | Connecting to Qdrant at 34.130.75.211:6333\n",
      "INFO     | httpx                     | HTTP Request: GET http://34.130.75.211:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: GET http://34.130.75.211:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO     | QdrantManager             | Successfully connected to Qdrant\n",
      "INFO     | httpx                     | HTTP Request: GET http://34.130.75.211:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO     | QdrantManager             | Collection 'professional_summaries' already exists.\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/professional_summaries/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/professional_summaries/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/professional_summaries/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/professional_summaries/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/professional_summaries/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | QdrantManager             | Collection 'technical_skills' already exists.\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/technical_skills/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/technical_skills/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/technical_skills/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/technical_skills/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/technical_skills/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | QdrantManager             | Collection 'experiences' already exists.\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/experiences/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/experiences/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/experiences/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/experiences/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | httpx                     | HTTP Request: PUT http://34.130.75.211:6333/collections/experiences/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO     | src.core.db_manager       |  Qdrant connection established\n",
      "INFO     | src.core.db_manager       | Initializing MongoDB connection...\n",
      "INFO     | src.core.db_manager       |  MongoDB connection established\n"
     ]
    }
   ],
   "source": [
    "from src.generation.call_llm import llm_json\n",
    "from src.generation.resume_generator import ResumeGenerator\n",
    "\n",
    "r = ResumeGenerator(llm_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3864fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"hi man\"\n",
    "from src.generation.prompts import SUMMARY_USER_PROMPT\n",
    "\n",
    "file = r._build_prompt(SUMMARY_USER_PROMPT, jd, res, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74545ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompt.txt\", \"w\") as f:\n",
    "    f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cfc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93818b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49423a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a0def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1d9675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     | ReliableBatchWorker       | Found resume document for resume_id: bb5fd9e7-a57a-4c3e-af0e-88a90445aaf1\n",
      "{\n",
      "  \"job_role\": \"oracle pl/sql developer\",\n",
      "  \"professional_summary\": [\n",
      "    \"IT professional with 9+ years of diverse experience in IT, including business analysis, applications management, strong software development skills and a solid technical aptitude for troubleshooting and problem solving.\",\n",
      "    \"Excel in identifying system needs, implementing multi - faceted application solutions, and working with a variety of operational systems, software, development languages and tools.\"\n",
      "  ],\n",
      "  \"technical_skills\": [\n",
      "    \"Operating Systems: Linux, Unix, IBM AIX 5.3 and Windows 95/98/2000/NT/XP\",\n",
      "    \"Languages: Oracle PL/SQL, UNIX Shell Scripting, Pro C, 4GL\",\n",
      "    \"Databases: Oracle8i, 9i, 10g & 11g, Informix\",\n",
      "    \"Tools: SQL*Plus, SQL* Loader, SQL Developer V 1.5.0.54.40, CTRL M\",\n",
      "    \"Supporting Software: Borland StarTeam, Putty, Smartbear Code Collaborator V7, Exceed\",\n",
      "    \"Middleware/Distributed: Web services\",\n",
      "    \"Others: HTTP/HTTPS, FTP\"\n",
      "  ],\n",
      "  \"experiences\": [\n",
      "    {\n",
      "      \"job_role\": \"PLSQL Lead Developer\",\n",
      "      \"responsibilities\": [\n",
      "        \"Working on the service request and business enhancements raised by client\",\n",
      "        \"Analyzing the business requirement and possible Impact of the proposed enhancement.\",\n",
      "        \"Propose a reliable solution for the requirement and preparing the technical understanding document.\",\n",
      "        \"Extensively involved in writing and managing PL/SQL stored procedures, functions, triggers and packages to meet the business requirements and update the existing objects based on service requests.\",\n",
      "        \"Created and maintained database objects like tables, views, Indexes, triggers, and synonyms to meet the business requirements.\",\n",
      "        \"Wrote complex SQL queries, Sub queries and nested loops for faster data retrieval.\",\n",
      "        \"Created Cursors and Ref Cursors to process the required data.\",\n",
      "        \"Used Bulk Collect and FOR ALL to DML multi-row from table.\",\n",
      "        \"Understanding the business logic to modify existing SQL Code and Performance Tuning, indexing, table partitioning.\",\n",
      "        \"Extensively worked through SQL Developer and SQL Plus for database development and tuning.\",\n",
      "        \"Used Oracle packages - DBMS STATS, UTL FILE\",\n",
      "        \"Created data load process to load data from OLTP sources into Netezza\",\n",
      "        \"Used exception handling methods along with pragma exception init in order to associate our own created exception names for the ease of debugging and displaying the error messages in the application.\",\n",
      "        \"Created batch jobs to load data into our database using UNIX Shell Script and Control - M scheduling.\",\n",
      "        \"Developed pl/sql program unit to test the business logic in testing environment.\",\n",
      "        \"Analysed and overviewed the database design for better understanding the relations, associations and dependencies within the database.\",\n",
      "        \"Provided technical design and documentation for new development and existing system enhancement.\",\n",
      "        \"Worked with testing team for test case and test script preparation.\",\n",
      "        \"Coordinated with QA and Testing team and provided the technical support for business implementation.\",\n",
      "        \"Worked as independent contributor for the project\"\n",
      "      ],\n",
      "      \"environment\": \"Oracle 9i,10g, SQL, PL/SQL,SQL*PLUS, MS Office, Microsoft Outlook, IBM AIX, Putty, Windows 7 professional and Unix.\"\n",
      "    },\n",
      "    {\n",
      "      \"job_role\": \"Oracle PL /SQL Developer\",\n",
      "      \"responsibilities\": [\n",
      "        \"Writing pl/sql procedure/packages/functions to resolve the daily task related issue to make them atomized.\",\n",
      "        \"Created scripts to load the data into database tables from flat files using SQL* Loader.\",\n",
      "        \"Created stored procedures with cursors to generate the reports.\",\n",
      "        \"Created various complex queries with joins, sub-queries, and nested queries in SQL queries.\",\n",
      "        \"Involved in loading files to tables using NZLOAD and extensively used NZSQL\",\n",
      "        \"Involved in production support by efficiently debugging the production issues.\",\n",
      "        \"Created indexes, constraints, triggers, synonyms in different schema.\",\n",
      "        \"Worked on Oracle Data dictionaries views to get information related to object\",\n",
      "        \"Worked on Bulk Collection and Pl/sql table for getting optimal performance.\",\n",
      "        \"Wrote Shell Scripts to do manipulation on vendor input files and loaded into database table\",\n",
      "        \"Generating various reports on requirements using PL/SQL, ProC and SQL * plus SPOOL command.\",\n",
      "        \"Involved in job scheduling using CTRL M.\",\n",
      "        \"Peer Review of code before turning over to production.\",\n",
      "        \"Preparation of Unit Test plan.\",\n",
      "        \"Perform System Testing, Release Testing and deploy the code.\",\n",
      "        \"Coordinating with onsite, attending regular hand-off and transition meetings for new projects.\",\n",
      "        \"Providing Knowledge transition on delivered effort to Production Support team.\"\n",
      "      ],\n",
      "      \"environment\": \"Oracle 9i,10g, SQL, PL/SQL,SQL*PLUS, MS Office, Microsoft Outlook, IBM AIX, Putty, Windows 7 professional and Unix.\"\n",
      "    },\n",
      "    {\n",
      "      \"job_role\": \"Oracle PL/SQL Developer\",\n",
      "      \"responsibilities\": [\n",
      "        \"To find out bugs in the application and rectify them.\",\n",
      "        \"To prepare document as per the changes in the code.\",\n",
      "        \"Developing Unix shell script to validate the input feed files received from different vendors.\",\n",
      "        \"Used various Shell Scripts and Scheduled jobs in CTRL M to run on regular intervals.\",\n",
      "        \"Involved in SQL Activities.\",\n",
      "        \"Involved in Unit testing, Debugging and Integration testing of the application.\",\n",
      "        \"Peer Review of code before turning over to production.\",\n",
      "        \"Managing Monthly release for all applications development, bug fixes.\",\n",
      "        \"Involved in client meetings.\",\n",
      "        \"Worked as independent contributors.\"\n",
      "      ],\n",
      "      \"environment\": \"Oracle 9i,10g, SQL, SQL*PLUS, MS Office, Microsoft Outlook, Putty, Windows 7 professional, Winscp and Unix .\"\n",
      "    },\n",
      "    {\n",
      "      \"job_role\": \"Oracle PL/SQL Developer\",\n",
      "      \"responsibilities\": [\n",
      "        \"Worked on project estimates, resourcing, status updates, project plan updates, and team coordination.\",\n",
      "        \"Preparation of Checklists, identification of Test Cases, preparing Test Plans.\",\n",
      "        \"Developed Pro C scripts with embedded pl/sql and sql.\",\n",
      "        \"Wrote Unix shell scripts to invoke the Pro C executables.\",\n",
      "        \"Scheduled all scripts in CTRL M.\",\n",
      "        \"Extensive Knowledge and working of Bulk Collect and Bulk Binding for data retrieval.\",\n",
      "        \"Wrote complex SQL queries, Sub queries, Cursors and Collections for faster data retrieval.\",\n",
      "        \"Involved in Performance Tuning for the SQL, PL/SQL scripts.\",\n",
      "        \"Coordination with the Release Management team to ensure the version control of the scripts execution in Production environment.\",\n",
      "        \"Provided knowledge transfer to other team members about the new technology and allocation of tasks to the team.\",\n",
      "        \"Involved in writing technical documentation, and writing test plan.\",\n",
      "        \"Coordinated with development team, project management, QA and provided necessary support.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"job_role\": \"Oracle PL/SQL Developer\",\n",
      "      \"responsibilities\": [\n",
      "        \"Working up with Service requests/change requests.\",\n",
      "        \"Impact analysis on existing system and provided appropriate solution.\",\n",
      "        \"Enhancing existing 4gl scripts to implement the business logic.\",\n",
      "        \"Structural changes to Informix database objects according to business logic.\",\n",
      "        \"Wrote Unix shell scripts to validate and manipulate the vendor files.\",\n",
      "        \"Created Unix Shell Scripts for automating the execution process of 4gl reports.\",\n",
      "        \"Used File Transfer Protocol (FTP) tool to transfer files from one server to other.\",\n",
      "        \"Worked on CTRL M for Scheduling Batch Jobs.\",\n",
      "        \"Involved in Unit testing, Integration test and writing the Test plan.\",\n",
      "        \"Preparing the technical documentation on changes done.\",\n",
      "        \"Release notes and Rollout and Backout plan.\",\n",
      "        \"Trained other team members on the functionality and operability of the application.\"\n",
      "      ],\n",
      "      \"environment\": \"Informix, 4GL, Crystal reports, Unix, Linux, IBM Unix servers running AIX 5.3IBM AIX, Borland Starteam, Putty, Smartbear Code Collaborator V7, Exceed\"\n",
      "    }\n",
      "  ],\n",
      "  \"resume_id\": \"bb5fd9e7-a57a-4c3e-af0e-88a90445aaf1\",\n",
      "  \"category\": \"oracle-developer\",\n",
      "  \"source_url\": \"https://www.hireitpeople.com/resume-database/70-oracle-developers-resumes/627621-oracle-pl-sql-developer-resume-san-antonio-tx-44\",\n",
      "  \"scraped_at\": \"2025-11-30 21:32:20.369000\",\n",
      "  \"qdrant_status\": \"ingested\",\n",
      "  \"processing_status\": \"scraped_success\",\n",
      "  \"processing_started\": \"2025-12-01 04:54:10.111000\",\n",
      "  \"ingested_at\": \"2025-12-01 04:54:54.197000\",\n",
      "  \"last_processed\": \"2025-12-01 04:54:54.197000\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.resume_ingestion.database import MongoDBManager\n",
    "import json\n",
    "\n",
    "manager = MongoDBManager()\n",
    "resume_id = \"bb5fd9e7-a57a-4c3e-af0e-88a90445aaf1\"\n",
    "\n",
    "resume = manager.get_resume_by_id(resume_id)\n",
    "\n",
    "if resume:\n",
    "    # Remove MongoDB _id for cleaner output\n",
    "    resume.pop('_id', None)\n",
    "    print(json.dumps(resume, indent=2, ensure_ascii=False, default=str))\n",
    "else:\n",
    "    print(f\"Resume not found: {resume_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb99aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
